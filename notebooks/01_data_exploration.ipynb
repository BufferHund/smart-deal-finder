{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration - Supermarket Brochures\n",
    "\n",
    "This notebook explores the collected brochure data and analyzes OCR results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(str(Path.cwd().parent / 'src'))\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available data\n",
    "data_dir = Path('../data/raw')\n",
    "\n",
    "if data_dir.exists():\n",
    "    files = list(data_dir.glob('**/*'))\n",
    "    image_files = [f for f in files if f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.pdf']]\n",
    "    \n",
    "    print(f\"Total files: {len(files)}\")\n",
    "    print(f\"Image/PDF files: {len(image_files)}\")\n",
    "    \n",
    "    # Group by supermarket\n",
    "    supermarkets = {}\n",
    "    for f in image_files:\n",
    "        supermarket = f.parent.name\n",
    "        if supermarket not in supermarkets:\n",
    "            supermarkets[supermarket] = []\n",
    "        supermarkets[supermarket].append(f)\n",
    "    \n",
    "    print(\"\\nFiles by supermarket:\")\n",
    "    for sm, files in supermarkets.items():\n",
    "        print(f\"  {sm}: {len(files)} files\")\n",
    "else:\n",
    "    print(\"No data collected yet. Run the scraper first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sample Brochure Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample brochure\n",
    "if image_files:\n",
    "    sample_image = Image.open(image_files[0])\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(sample_image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Sample Brochure: {image_files[0].name}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No images to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. OCR Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OCR results if available\n",
    "processed_dir = Path('../data/processed')\n",
    "\n",
    "if processed_dir.exists():\n",
    "    json_files = list(processed_dir.glob('**/*.json'))\n",
    "    \n",
    "    if json_files:\n",
    "        # Load a sample result\n",
    "        with open(json_files[0], 'r') as f:\n",
    "            ocr_result = json.load(f)\n",
    "        \n",
    "        print(f\"OCR Engine: {ocr_result.get('ocr_engine', 'N/A')}\")\n",
    "        print(f\"Number of text boxes: {ocr_result.get('num_boxes', 0)}\")\n",
    "        \n",
    "        # Display first few text boxes\n",
    "        print(\"\\nSample extracted text:\")\n",
    "        for i, box in enumerate(ocr_result.get('text_boxes', [])[:10]):\n",
    "            print(f\"{i+1}. {box['text']} (confidence: {box['confidence']:.2f})\")\n",
    "    else:\n",
    "        print(\"No OCR results found. Run the OCR pipeline first.\")\n",
    "else:\n",
    "    print(\"No processed data yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Text Confidence Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze confidence scores\n",
    "if json_files:\n",
    "    confidences = [box['confidence'] for box in ocr_result.get('text_boxes', [])]\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(confidences, bins=20, edgecolor='black', alpha=0.7)\n",
    "    plt.xlabel('Confidence Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of OCR Confidence Scores')\n",
    "    plt.axvline(np.mean(confidences), color='red', linestyle='--', label=f'Mean: {np.mean(confidences):.2f}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Mean confidence: {np.mean(confidences):.3f}\")\n",
    "    print(f\"Median confidence: {np.median(confidences):.3f}\")\n",
    "    print(f\"Min confidence: {np.min(confidences):.3f}\")\n",
    "    print(f\"Max confidence: {np.max(confidences):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bounding Box Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize bounding boxes on image\n",
    "if image_files and json_files:\n",
    "    # Load image\n",
    "    img = cv2.imread(str(image_files[0]))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Draw bounding boxes\n",
    "    for box in ocr_result.get('text_boxes', []):\n",
    "        bbox = box['bbox']\n",
    "        confidence = box['confidence']\n",
    "        \n",
    "        # Color based on confidence (green = high, red = low)\n",
    "        color = (int(255 * (1 - confidence)), int(255 * confidence), 0)\n",
    "        \n",
    "        cv2.rectangle(\n",
    "            img,\n",
    "            (bbox['x_min'], bbox['y_min']),\n",
    "            (bbox['x_max'], bbox['y_max']),\n",
    "            color,\n",
    "            2\n",
    "        )\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('OCR Bounding Boxes (Green = High Confidence, Red = Low Confidence)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Entity Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern analysis for prices, products, etc.\n",
    "import re\n",
    "\n",
    "if json_files:\n",
    "    texts = [box['text'] for box in ocr_result.get('text_boxes', [])]\n",
    "    \n",
    "    # Find potential prices\n",
    "    price_pattern = r'\\d+[,.]\\d{2}\\s*â‚¬?'\n",
    "    prices = [text for text in texts if re.search(price_pattern, text)]\n",
    "    \n",
    "    # Find percentages (discounts)\n",
    "    percent_pattern = r'\\d+\\s*%'\n",
    "    discounts = [text for text in texts if re.search(percent_pattern, text)]\n",
    "    \n",
    "    print(f\"Potential prices found: {len(prices)}\")\n",
    "    print(\"Sample prices:\", prices[:10])\n",
    "    print(f\"\\nPotential discounts found: {len(discounts)}\")\n",
    "    print(\"Sample discounts:\", discounts[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Run the data collection script to download more brochures\n",
    "2. Process images with OCR pipeline\n",
    "3. Manually annotate sample data for training\n",
    "4. Train entity recognition model\n",
    "5. Evaluate and refine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
